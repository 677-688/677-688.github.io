---
date: 2025-12-28 18:31:03
title: 计算机体系结构
permalink: /pages/535598
categories:
  - 第1章 计算机系统知识
tags:
  - 第1章 计算机系统知识
coverImg: /backgrounds/212.jpg
---
# 计算机体系结构

| **层面**                        | **定义**                              | **关注点**   | **举例**              |
| ----------------------------- | ----------------------------------- | --------- | ------------------- |
| **体系结构**  <br>（Architecture）  | **程序员可见的抽象**  <br>指令集架构（ISA）定义"做什么" | 功能特性、编程模型 | x86-64、ARMv8、RISC-V |
| **组成/组织**  <br>（Organization） | **硬件组件及其连接**  <br>实现体系结构的方式 决定"怎么做" | 内部结构、数据通路 | 流水线深度、缓存层次、总线结构     |
| **实现**  <br>（Implementation）  | **物理实现细节** 解决"用什么做"                 | 物理设计、制造工艺 | 晶体管布局、时钟频率、功耗       |
## 1. 计算机体系结构的发展

### 1.1 计算机体系结构发展概述
#### 1.1.1 早期发展阶段（1940s-1960s） -- **奠定基础的时代**

- **冯·诺依曼体系结构**（1945）
    
    - 存储程序概念
	    - 程序和数据存储在同一存储器
		- 指令可像数据一样被修改
		- 实现真正的通用计算
    - 五大部件：运算器、控制器、存储器、输入设备、输出设备
    - 顺序执行指令
	    - 取指令 → 译码 → 执行 → 写回
        
- **电子管→晶体管→集成电路**的硬件演进
    
#### 1.1.2 经典体系结构时期（1970s-1980s） -- **CISC的黄金时代**

- **CISC（复杂指令集计算机）** 
    
    - 让硬件完成复杂功能，简化编译器设计
    - 丰富的指令集
	    - 数百条指令
		- 复杂寻址方式
		- 可变长度指令
    - 微程序控制
	    - 复杂指令 → 微程序ROM → 微指令序列 → 控制信号
    - 代表：x86架构
        
- **流水线技术**的出现
- **缓存（Cache）** 的引入
	- 解决CPU与主存速度不匹配

#### 1.1.3 RISC革命（1980s-1990s） -- **精简化的胜利**

- **背景问题**（John Cocke，1970s IBM研究）：
	- 20%的简单指令占80%的使用时间
	- 复杂指令很少使用但增加硬件复杂度
- **精简指令集计算机**
    
    - 简化指令集
	    - 只保留高频使用的指令
		- 指令长度固定（通常32位）
		- 简化寻址方式
	- **加载/存储架构**：
		```
		RISC风格（ARM/MIPS）
		LDR R1, [`R2`]     ; 加载到寄存器
		ADD R3, R1, R4   ; 寄存器运算
		STR R3, [R5]     ; 存回内存
		
		对比CISC（x86）
		ADD [AX], [BX]   ; 直接内存操作
		```
	 
	 - 硬布线控制	
		- 取代微码控制
		- 提高指令执行速度
	 - 流水线深度优化
	 - 代表：ARM、MIPS、SPARC
        
- **超标量（Superscalar）** 架构 ： 单个时钟周期发射多条指令
- **乱序执行（Out-of-Order Execution）** ： 按序取指 → 寄存器重命名 → 乱序执行 → 按序提交
	- **优势**：
		- 克服数据依赖限制
		- 提高功能单元利用率
    

#### 1.1.4 并行与多核时代（2000s-2010s） -- **并行化的必然选择**

- **单核性能极限**

```
	1. 功耗墙（Power Wall）：
	   Pentium 4：130W → 无法继续提高频率
	   
	2. 存储墙（Memory Wall）：
	   CPU速度 ↑ 10倍/10年
	   内存速度 ↑ 1.1倍/10年
	
	3. ILP墙（指令级并行墙）：
	   程序固有并行度有限
	   超标量收益递减
```

- **多核处理器**成为主流
    
    - 解决功耗墙问题 
		- 功耗效率：
		- 单核：频率↑ → 功耗∝频率³
		- 多核：频率不变，核心数↑ → 性能线性增长
    - 片上多处理器（CMP）
	    - 早期：多个独立芯片封装
	    - 现在：单芯片集成多个完整核心
	    - **共享资源设计**：

			```
					┌─────────┬─────────┬─────────┐
					│  Core 1 │  Core 2 │  Core 3 │
					├─────────┴─────────┴─────────┤
					│        共享L3缓存            │
					├─────────────────────────────┤
					│       内存控制器/互连         │
					└─────────────────────────────┘
			```
- **SIMD扩展**（MMX、SSE、AVX）
    
- **异构计算**兴起
    
    - CPU + GPU协同
	    - CPU：复杂控制流，低并行度任务
	    - GPU：简单控制流，高并行度任务
	- **NVIDIA CUDA**（2007）：
		- 通用GPU计算框架
		- 开启GPGPU时代
	- **APU概念**（AMD Fusion，2011）：
		- CPU + GPU集成在同一芯片
		- 共享内存，减少数据拷贝
        
#### 1.1.5 现代发展趋势（2020s-现在） -- **专用化与智能化**

- **领域专用架构（DSA）**
    
    - AI加速器（TPU、NPU）
    - 可重构计算
	    - **FPGA动态重构**
		- 运行时根据任务调整硬件
        
- **存算一体**
    
    - **传统冯·诺依曼瓶颈**：
	    - CPU计算1次：约1pJ（皮焦）
		- 从内存取数据：约100pJ
		- 能耗比：1:100
    - 减少数据搬运
    - **近内存计算**
	    - 计算单元靠近内存
		- HBM（高带宽内存）+ 计算逻辑
	- **内存内计算**：
	    - 利用内存单元本身进行计算
	    - 电阻式内存（ReRAM）、相变内存（PCM）
        
- **量子计算架构**
	- 叠加态：同时表示0和1
	- 纠缠态：量子位相互关联
- **神经形态计算**
	- **事件驱动**：有事件才处理
	- **异步通信**：无全局时钟
	- **存算一体**：突触存储权重并计算
- **Chiplet与先进封装**
	- 传统：单芯片集成所有功能
	- Chiplet：多个小芯片（Chiplet）通过先进封装集成
- **安全架构强化**
	- **硬件安全特性**：
	- **Intel SGX**：可信执行环境
	- **ARM TrustZone**：硬件隔离安全区
	- **内存安全**：防止缓冲区溢出等攻击

#### 发展总结

#### 技术演进图谱

``` text

时间轴：    1940s     1950s     1960s     1970s     1980s     1990s     2000s     2010s     2020s
          ────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┼────
硬件：    电子管 → 晶体管 → IC → LSI → VLSI → 微处理器 → 多核 → 众核 → 异构 → Chiplet
          ────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┼────
架构：    冯·诺依曼 → 微程序 → CISC主导 → RISC革命 → 超标量 → 多核 → GPU计算 → DSA → 存算一体
          ────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┼────
并行：     无     →    无     →  向量机  →  流水线  →超标量 → 乱序执行 → 多线程 → 众核 → 异构并行
          ────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┼────
性能：  1 OPS → 10K OPS → 1M OPS → 10M OPS → 1G OPS → 10G OPS → 1T OPS → 10T OPS → 1P OPS

```
#### 关键趋势总结

1. **抽象层次不断提升**：
    
    晶体管 → 逻辑门 → 功能单元 → 处理器核心 → 多核系统 → 计算集群
    
2. **设计哲学演变**：
    
    简单硬件（早期）→ 复杂硬件（CISC）→ 简单硬件+智能编译（RISC） → 并行硬件（多核）→ 专用硬件（DSA）
    
3. **性能驱动力转变**：
    
    频率提升 → 指令级并行 → 数据级并行 → 线程级并行 → 任务级并行
    
4. **未来方向**：
    
    - **专用化**：针对特定负载优化
    - **异构化**：多种计算单元协同
    - **智能化**：硬件自适应调整
    - **能效优先**：性能/瓦特成为关键指标

### 1.2 计算机体系结构的分类

#### 1.2.1 宏观分类（按处理机数量）

**1. 单处理机系统**

- **特点**：单个CPU执行指令
- **分类**：
    - 单用户系统：**一人一机，独占所有** —— 同一时间只有一个用户独占整个计算机系统的所有资源。
    - 多道程序系统：**一芯多用，内存分工** —— 单个CPU通过内存中同时驻留多个程序并切换执行，**提高资源利用率**。
    - 分时系统：**多人共享，轮转服务** —— 多个用户通过终端共享同一台计算机，CPU采用**时间片轮转**方式快速切换，为每个用户提供**交互式体验**。

**2. 多处理机系统**

- **对称多处理（SMP）** ：**对等协作，资源共享**
    - 所有处理器地位相同、能力对等
    - **共享统一的内存和I/O资源**
    - **单一操作系统统一管理和调度**
        
- **非对称多处理（AMP）** : **主从分工，专事专办**

	> 一个主处理器负责系统控制和任务分配，多个从处理器**专门处理特定类型任务**（如I/O处理、浮点运算等）

    - 主从结构
    - 专用处理器分工

**3. 多计算机系统**

- **集群系统（Cluster）**：**独立自治，消息互联**

	> 由**多个独立计算机**组成的**松耦合系统**，各计算机拥有**独立的内存空间**，通过**消息传递**方式在网络上进行通信协作。

    - 松耦合系统
    - 各自独立内存
    - 消息传递通信
        
- **大规模并行处理（MPP）**：**千芯互联，高速协作**

	> 由**数千个处理器**通过**专用高速互连网络**紧密连接，形成单一、统一的高性能计算系统。
	
    - 专用高速互连
    - 数千个处理器

**4. 分布式系统**：**地理分散，透明共享**

- **特点**：

    > 将**地理分布**的计算机资源通过网络连接，为用户提供**透明访问**的统一服务，实现**资源共享**和**高可用性**。

	- 地理分布
    - 透明访问
    - 资源共享
    - 高可用性

**5. 发展趋势**

> 单机 → SMP → 集群 → 云 → 边缘计算

#### 1.2.2 微观分类（按并行程度）

1. **Flynn 分类法（最经典）**

	基于**指令流**和**数据流**的数量

|**类型**|**指令流**|**数据流**|**特点**|**代表**|
|---|---|---|---|---|
|**SISD**  <br>单指令单数据|1|1|传统串行计算机|早期计算机|
|**SIMD**  <br>单指令多数据|1|多|数据级并行|GPU、向量机|
|**MISD**  <br>多指令单数据|多|1|理论上存在  <br>实际很少使用|容错系统|
|**MIMD**  <br>多指令多数据|多|多|任务级并行|多核CPU、集群|
2. **按并行粒度分类**

	```
		 宏观并行
		    ↓
		┌─────────────────┐
		│   进程级并行     │ ← 粗粒度
		├─────────────────┤
		│   线程级并行     │ ← 中粒度
		├─────────────────┤
		│   指令级并行     │ ← 细粒度
		├─────────────────┤
		│   数据级并行     │ ← 细粒度
		└─────────────────┘
	```
	
	**详细展开**：
	 
	**A. 线程/进程级并行（粗粒度）**
	
	```
		进程1：┌───┬───┬───┐
		进程2：   └───┬───┬───┐
		进程3：       └───┬───┘
		      时间→
	```
	- **多道程序设计**
	- **多任务处理**
	- **多线程编程**

	**B. 指令级并行（ILP，细粒度）**
	
	```
		传统：取指 → 译码 → 执行 → 访存 → 写回
		流水线：IF → ID → EX → MEM → WB
		         IF → ID → EX → MEM → WB
		              IF → ID → EX → MEM → WB
	```
	
	**技术实现**：
	
	1. **流水线（Pipeline）**
	2. **超标量（Superscalar）**
	    
	```
	    时钟周期1：指令A 指令B 指令C
	    时钟周期2：指令D 指令E 指令F
	```
	    
	1. **超长指令字（VLIW）**
	2. **乱序执行（OoOE）**
	
	 **C. 数据级并行（DLP，细粒度）**
	
	- **向量处理** 
	- **SIMD扩展**
	
	**D. 任务级并行（TLP，中粒度）**
	
	- **多核处理器**
	 
	```
	    Core1：┌─────任务A─────┐
	    Core2：┌─────任务B─────┐
	    Core3：┌─────任务C─────┐
	```
	    
	- **同时多线程（SMT）**
	    
	    - Intel Hyper-Threading
	    - 单个核心"虚拟"为多个逻辑处理器

3. **按内存架构分类**

	**A. 共享内存系统**
	
	```
	     ┌──────┐  ┌──────┐  ┌──────┐
	     │ CPU1 │  │ CPU2 │  │ CPU3 │
	     └──────┘  └──────┘  └──────┘
	          ↓         ↓         ↓
	     ┌──────────────────────────┐
	     │       共享内存            │
	     └──────────────────────────┘
	```
	
	- **UMA（均匀内存访问）**
	    
	    - 访问时间一致
	    - SMP系统
	        
	- **NUMA（非均匀内存访问）**
	    
	    - 访问时间不一致
	    - 现代多处理器系统
	
	**B. 分布式内存系统**
	
	```
	    ┌──────┐      ┌──────┐      ┌──────┐
		│ CPU+ │      │ CPU+ │      │ CPU+ │
		│内存1 │      │内存2 │      │内存3 │
		└──────┘      └──────┘      └──────┘
		     ↓消息传递        ↓消息传递
		    网络互连
	```


4. **现代混合架构**

	**A. CPU+GPU异构系统**
	
	```
		┌───────────────────────┐
		│        CPU（控制）     │
		│  多核，通用计算         │
		└───────────┬───────────┘
		            ↓ PCIe
		┌───────────────────────┐
		│        GPU（计算）     │
		│  数千核心，数据并行     │
		└───────────────────────┘
	```
	
	**B. 存算一体架构**
	
		传统：CPU → 内存总线 → DRAM → 处理 → 返回
		存算：在内存内部直接计算

#### 1.2.3 分类的总结与趋势

1. 发展规律

	- **从串行到并行**
	- **从同构到异构**
	- **从通用到专用**
	- **从计算中心到存算一体**

2. 分类关系总结

```
	宏观（系统级）                 微观（处理器级）
	    ↓                               ↓
	┌──────────────┐              ┌──────────────┐
	│ 单处理机系统  │              │    SISD      │
	├──────────────┤              ├──────────────┤
	│ 多处理机系统  │ ← 对应 →     │ SIMD/MIMD    │
	├──────────────┤              ├──────────────┤
	│ 多计算机系统  │              │ 数据/任务并行 │
	└──────────────┘              └──────────────┘
```
 3. 未来方向
	- **专用化**：AI芯片、量子芯片
	- **集成化**：Chiplet、3D堆叠
	- **智能化**：自适应架构
	- **能效优先**：每瓦性能优化
	- **软硬件协同**：编译器感知架构
### 1.3 指令系统

> 一个处理器支持的指令和指令的字节级编码称为其指令集体系结构（ISA） 
#### 1.3.1 按复杂度

- **CISC**：**硬件复杂化，指令多功能化**
- **RISC**：**硬件精简化，指令单功能化**
#### 1.3.2 按存储模型

- **堆栈型**：**操作数在栈顶，隐含寻址**
- **累加器型**：**专用累加器，操作中心化**
- **寄存器-存储器型**：**内存直接操作，灵活高效**
- **加载/存储型**：**内存访问受限，寄存器为中心**
#### 1.3.3 现代趋势

- **模块化设计**：**基础+扩展，按需定制**
- **内部微码化**：**CISC外表，RISC内核**
- **向量化扩展**：**单指令多数据，并行加速**

### 1.4 阵列处理机、并行处理机、多处理机

1. **阵列处理机**：

> **数据并行，同步执行** —— 大量**相同处理单元**组成规则阵列，在**统一控制器**指挥下**同步执行同一条指令**处理不同数据。

2. **并行处理机**：

> **广义并行，指令多样** —— **多种并行计算系统**的总称，包括SIMD、MIMD等多种模式，强调**同时执行多个任务或操作**。

3. **多处理机**：

> **独立协作，异步并行** —— **多个完整处理器**通过互连网络连接，**独立执行不同程序或线程**，通过共享内存或消息传递协作。


## 2. 存储系统

### 2.1 存储器的层次结构

```
                  容量小、速度快、成本高
                  
      ┌─────────────────────────────────────┐
      │          CPU寄存器                   │ ← 1周期，~1KB
      └─────────────────────────────────────┘
                     ↓
      ┌─────────────────────────────────────┐
      │       高速缓存（Cache）              │
      │   L1: 2-4周期，32-64KB              │
      │   L2: 10-20周期，256KB-1MB          │
      │   L3: 30-50周期，8-32MB             │
      └─────────────────────────────────────┘
                     ↓
      ┌─────────────────────────────────────┐
      │         主存储器（RAM）              │ ← 100-300周期，8-128GB
      └─────────────────────────────────────┘
                     ↓
      ┌─────────────────────────────────────┐
      │      辅助存储器（磁盘/SSD）          │ ← 10^5-10^6周期，1-10TB
      └─────────────────────────────────────┘
                     ↓
      ┌─────────────────────────────────────┐
      │      三级存储器（磁带/光盘）          │ ← 离线，10-100TB+
      └─────────────────────────────────────┘
                      
                  容量大、速度慢、成本低
```

#### 层次化原理

- 局部性原理**
	
		```
		     // 时间局部性：最近访问的很快会再访问
		    for (i=0; i<100; i++) {
		        sum += array[i];  // sum被重复访问
		    }
		    
		    // 空间局部性：访问附近位置的可能性大
		    for (i=0; i<100; i++) {
		        array[i] = i;    // 连续内存访问
		    }
		```
		
- 访问频率与成本权衡
	
		性价比优化：CPU寄存器 > Cache > 内存 > SSD > HDD

### 2.2 存储器的分类

#### 2.2.1 按所处位置分类

**内部存储器**：位于计算机主机内部，CPU可直接访问

- **寄存器**：CPU内部的极高速存储单元，容量最小，速度最快
- **高速缓存**：CPU与主存之间的高速缓冲，分为L1、L2、L3等层次
- **主存储器**：计算机的主要内存，即RAM，CPU通过总线直接访问

**外部存储器**：位于主机外部，需要通过I/O接口访问

- **磁盘存储器**：包括硬盘、软盘（已淘汰）
- **固态存储器**：SSD、U盘、存储卡
- **光存储器**：CD、DVD、蓝光光盘
- **磁带存储器**：用于数据备份和归档

#### 2.2.2 按构成材料分类

 **半导体存储器**：基于半导体技术制造

- **易失性存储器**：断电后数据丢失
    
    - **SRAM**：静态随机存取存储器，6晶体管结构，速度快，用于Cache
    - **DRAM**：动态随机存取存储器，需定期刷新，用于主内存
        
- **非易失性存储器**：断电后数据保留
    
    - **ROM**：只读存储器，固件存储
    - **PROM**：可编程只读存储器，用户可编程一次
    - **EPROM**：可擦除可编程只读存储器，紫外线擦除
    - **EEPROM**：电可擦除可编程只读存储器
    - **Flash**：闪存，用于SSD、U盘

**磁表面存储器**：利用磁性材料存储

- **硬盘**：金属盘片表面涂覆磁性材料
- **磁带**：塑料带基涂覆磁性材料
    
**光存储器**：利用激光读写

- **CD**：压缩光盘，700MB容量
- **DVD**：数字多功能光盘，4.7-17GB
- **Blu-ray**：蓝光光盘，25-128GB
#### 2.2.3 按工作方式分类
 
- **RAM**：读写存储器，包括SRAM和DRAM
- **ROM**：只读存储器，只能读取
    
#### 2.2.4 按访问方式分类

- **按地址访问**
- **按内容访问**
#### 2.2.5 按寻址方式分类

- **随机存储器**：可随机读写任意地址，访问任何地址的时间相同
- **顺序存储器**：必须按顺序访问，访问时间与数据位置相关
- **直接存储器**：先直接定位大致位置，再顺序访问
### 2.3 相联存储器

> **按内容寻址而非地址** —— 并行比较所有存储单元的内容，**直接找到匹配项**。

```
		          ┌─────────────────┐
			输入 → │ 比较逻辑阵列 │ ← 并行比较所有单元
		          ├─────────────────┤
		          │  存储单元阵列   │ ← 存储(key, value)对
		          ├─────────────────┤
			输出 → │ 匹配选择电路   │ ← 输出匹配结果
		          └─────────────────┘
```

#### 2.3.1 应用场景

	1. 高速缓存（Cache的标签存储）
	2. 虚拟内存TLB（页表缓存）
	3. 数据库加速
	4. 网络路由表查找
	5. 模式匹配引擎
	6. 神经网络计算
#### 2.3.2 优缺点

	优点：
	1. 查找速度快（O(1)时间复杂度）
	2. 适合模糊匹配
	3. 硬件并行度高
	
	缺点：
	4. 硬件成本高（每个单元需比较器）
	5. 功耗较大
	6. 容量受限
	7. 制造工艺复杂
### 2.4 高速缓存

> 用来存放当前最活跃的程序和数据，特点是：位于 CPU 与主存之间，容量一般在几千字节和几兆字节之间，速度比主存快 5-10 倍，由快速半导体存储器构成，其内容是主存局部域的副本；
> 设计目标是 成本允许的条件下达到较高的命中率，是存储系统拥有最短的平均访问时间。

#### 2.4.1 组成

- 存储部分用来存放主存的部分拷贝信息
- 控制部分用来判断 CPU 要访问的信息是否在 Cache 存储中，
	- 若在即为命中。命中时直接对 Cache 存储器寻址；
	- 未命中时要按照替换原则决定主存的一块信息放到 Cache 存储器的哪一块里。
#### 2.4.2 地址映像方法

> 地址映像：CPU工作时，送出的时主存单元的地址，而应从 Cache 存储器中读写信息，这就需要将主存地址转换为 Cache 存储器的地址

1. 直接映射（Direct Mapped）
	1. 主存的块与 Cache 块的对应关系是固定的，主存的块只能放在 Cache 的相同块中
	2. 地址变换：只要主存区号与 Cache 中记录的主存区号相同就命中，块内地址就是主存地址中给的低位地址
	3. 优点是：地址变换简单
	4. 缺点是：灵活性差，不同区号中块号相同的块无法调入 Cache，导致有空着的块也不能用
2. 全相联映像
	1. 主存与 Cache 分成大小相同的块，允许主存的任一块都可以调入 Cache 的任意一块的空间中。
	2. 地址变换：利用主存地址高位表示的主存块号与 Cache 中所有单元中记录的主存块号比较，
		1. 相同即命中，单元编号就对应要访问 Cache 的块号，访问相应的存储单元
	3. 优点是：主存的块调入 Cache 的位置不受限制，十分灵活
	4. 缺点是：无法直接从主存块号中获取 Cache 的快好，变换比较复杂，速度慢
3. 组相联映像
	1. 前两种方法的折中，把块再分成组；
	2. 地址变换：通过直接映像方式找到组，通过全相联映像方式找到块。

#### 2.4.3 替换算法

> 目的就是使 Cahce 获得尽可能高的命中率

1. 随机替换算法：用随机数发生器产生一个要替换的块号，将块替换出去
2. 先进先出算法：最先进入信息块替换出去
3. 近期最少使用算法：将近期最少使用的信息块替换出去
4. 优化替换算法：先执行一次程序，统计块替换情况，根据这个情况，在第二次执行程序时便可以用最有效的方式替换

#### 2.4.4 性能分析

1. **性能指标**
	- **命中率**：Cache命中的访问次数占总访问次数的比例，是衡量Cache有效性的最重要指标。
	- **Miss率**：1 - 命中率，表示未命中的比例。
	- **平均访问时间**：综合命中时间和Miss代价的计算结果，反映整体性能。
	- **Miss代价**：处理一次Cache Miss所需的额外时间，包括访问下一级存储和可能的替换操作。
	- **带宽利用率**：Cache系统有效利用内存带宽的能力。

2. **Miss分类**
	- **强制性不命中**：第一次访问某数据必然发生的不命中，也称为冷启动不命中。只能通过预取技术减少。
	- **容量不命中**：由于Cache容量不足，无法容纳工作集导致的不命中。增加Cache容量或优化程序数据局部性可改善。
	- **冲突不命中**：由于映射冲突导致的不命中（直接映射和组相联中存在）。增加相联度或优化数据布局可减少。
	- **一致性不命中**：在多处理器系统中，由于Cache一致性维护导致的不命中。

3. **性能计算公式**
	- 平均访问时间 = 命中时间 + Miss率 × Miss代价
	- 对于多级Cache：AMAT = L1命中时间 + L1 Miss率 × (L2命中时间 + L2 Miss率 × (L3命中时间 + L3 Miss率 × 内存访问时间))

4. **性能影响因素**
	- **程序行为**：访问模式的空间局部性和时间局部性。
	- **Cache参数**：容量、块大小、相联度。
	- **替换算法**：影响容量和冲突不命中的处理效率。
	- **预取效果**：减少强制性不命中的能力。
	- **写策略**：写直达vs写回，影响写操作性能。
	- **多核影响**：共享Cache的竞争和一致性开销。

5. **优化技术**
	- **增大Cache容量**：减少容量不命中，但可能增加命中时间。
	- **优化块大小**：大块提高空间局部性但可能增加冲突和浪费。
	- **增加相联度**：减少冲突不命中但增加硬件成本和命中时间。
	- **使用Victim** **Cache**：存放最近被替换的块，减少冲突不命中的影响。
	- **预取技术**：主动加载可能使用的数据，减少强制性不命中。
	- **编译器优化**：重新组织数据布局和访问模式，提高局部性。

#### 2.4.5 多级 Cache

1. **L1 Cache**：最接近CPU，分为指令Cache和数据Cache（哈佛架构），容量小（32-64KB），速度最快（2-4周期延迟）。
2. **L2 Cache**：容量较大（256KB-1MB），统一存储指令和数据，延迟较高（10-20周期）。
3. **L3 Cache**：多核共享的大容量Cache（8-64MB），延迟更高（30-50周期），用于减少对主存的访问。
4. L4 Cache（可选）：某些系统使用eDRAM作为第四级Cache（128MB+），延迟约80-100周期。

### 2.5 虚拟存储器

> 对主存的一种抽象，使用虚拟地址（由 CPU 生成）的概念来访问主存，使用专门的内存管理单位将虚拟地址转换为物理地址后访问主存。
> 实质是对物理存储设备进行逻辑化处理，并将统一的逻辑视图呈现给用户，用户操作的是虚拟设备，无需关心底层的物理环境。

**核心机制**：

1. **地址空间虚拟化**：为每个进程提供独立的虚拟地址空间
2. **按需分页**：只加载需要的内存页到物理内存
3. **自动换页**：内存不足时将不常用的页交换到磁盘
4. **地址转换**：通过页表将虚拟地址映射到物理地址

**关键组件**：

- **页表**：记录虚拟页到物理页的映射关系
- **TLB**：缓存常用页表项，加速地址转换
- **MMU**：硬件内存管理单元，执行地址转换

**主要优势**：

- **透明扩展**：程序可使用超过物理内存的空间
- **内存隔离**：进程间互不干扰
- **简化管理**：程序看到连续空间，无需关心物理分布

**性能代价**：

- **地址转换开销**：需要查页表
- **缺页中断**：访问不在内存的页需要磁盘I/O
- **管理复杂性**：需要操作系统和硬件协同

### 2.6 外存储器

> 计算机外部存储设备，用于**长期保存数据**，**断电不丢失**，通过I/O接口与主机连接。

**硬盘**：

- **机械硬盘**：磁性盘片旋转，磁头读写数据
- **固态硬盘**：闪存芯片存储，无机械部件，速度快

**移动存储**：

- **U盘**：USB接口闪存设备
- **存储卡**：SD卡、TF卡等，用于相机手机

**光存储**：

- **光盘**：CD、DVD、蓝光光盘，激光读写

**磁带**：

- 顺序访问，容量大（可达数十TB）
- 主要用于数据备份和归档

### 2.7 磁盘阵列技术

> 将多个物理硬盘组合成**一个逻辑存储单元**，通过**数据分布**和**冗余**技术提高**性能**、**容量**和**可靠性**。

#### RAID各级别对比表

| **特性维度**  | **RAID 0**                         | **RAID 1**                           | **RAID 5**                        | **RAID 6**                   | **RAID 10**                         | **RAID 50**                      | **RAID 60**                        |
| --------- | ---------------------------------- | ------------------------------------ | --------------------------------- | ---------------------------- | ----------------------------------- | -------------------------------- | ---------------------------------- |
| **中文名称**  | 条带化                                | 镜像                                   | 带奇偶校验的条带化                         | 双重奇偶校验条带化                    | 镜像+条带化                              | RAID 5+RAID 0                    | RAID 6+RAID 0                      |
| **最小磁盘数** | 2                                  | 2                                    | 3                                 | 4                            | 4                                   | 6                                | 8                                  |
| **容量利用率** | 100%                               | 50%                                  | (n-1)/n                           | (n-2)/n                      | 50%                                 | (n-g)/n  <br>（g=组数）              | (n-2g)/n  <br>（g=组数）               |
| **容错能力**  | 无                                  | 允许1块磁盘故障                             | 允许1块磁盘故障                          | 允许2块磁盘故障                     | 每组镜像允许1块故障                          | 每组允许1块故障                         | 每组允许2块故障                           |
| **读性能**   | 优秀                                 | 优秀                                   | 优秀                                | 优秀                           | 优秀                                  | 优秀                               | 优秀                                 |
| **写性能**   | 优秀                                 | 一般                                   | 中等（有写惩罚）                          | 较差（双重写惩罚）                    | 优秀                                  | 中等                               | 较差                                 |
| **随机I/O** | 优秀                                 | 好                                    | 好                                 | 中等                           | 优秀                                  | 好                                | 中等                                 |
| **连续I/O** | 优秀                                 | 好                                    | 好                                 | 好                            | 优秀                                  | 优秀                               | 优秀                                 |
| **重建复杂度** | 不适用                                | 简单                                   | 中等                                | 复杂                           | 中等                                  | 中等                               | 复杂                                 |
| **重建时间**  | 不适用                                | 短                                    | 长                                 | 很长                           | 中等                                  | 长                                | 很长                                 |
| **成本效益**  | 高                                  | 低                                    | 高                                 | 中等                           | 低                                   | 中等                               | 中等                                 |
| **数据安全性** | 低                                  | 高                                    | 中等                                | 高                            | 高                                   | 高                                | 极高                                 |
| **典型应用**  | 视频编辑  <br>临时数据                     | 系统盘  <br>关键数据                        | 文件服务器  <br>通用存储                   | 关键数据存储  <br>高可用需求            | 数据库  <br>高性能应用                      | 中等规模  <br>企业存储                   | 大规模  <br>关键数据                      |
| **优缺点**   | **优点**：性能最佳，容量100%  <br>**缺点**：无冗余 | **优点**：可靠性高，读性能好  <br>**缺点**：容量浪费50% | **优点**：平衡性能与容量  <br>**缺点**：写性能有开销 | **优点**：双盘容错  <br>**缺点**：写开销大 | **优点**：性能+可靠性  <br>**缺点**：成本高，容量50% | **优点**：大容量+较好性能  <br>**缺点**：配置复杂 | **优点**：大容量+高容错  <br>**缺点**：配置复杂成本高 |

### 2.8 存储域网络

> **专用的高速网络**，将**存储设备**与**服务器**连接，提供**块级**的数据访问服务，构成一个**独立的存储资源池**。

## 3. 输入/输出技术

### 3.1 微型计算机中最常用的内存与接口编址方法

- 内存与接口地址独立编址方式：
	- **内存和I/O接口使用完全分离的地址空间**
	- CPU通过**不同的指令**（内存用MOV，I/O用IN/OUT）访问**不同的地址范围**，内存地址和I/O地址互不重叠、各自独立编址。

- 内存与接口地址统一编址方式
	- **内存和外设共享同一地址空间**
	- 内存地址和I/O端口地址**统一编号在同一线性地址空间内**，CPU**使用相同的访存指令**（如MOV、LDR）访问内存和外设寄存器，**无法通过地址值区分**访问的是内存还是I/O设备。

### 3.2 直接程序控制

- 程序控制I/O方法 - **CPU全程主导，软件决定流程**
	- **原理**：CPU完全负责整个I/O过程。CPU通过**轮询**的方式，反复检查设备状态寄存器，直到设备准备好，然后一个字（或一个字节）地传输数据。
	- **缺点**：CPU的绝大部分时间都被浪费在等待低速设备上，效率极低。也称为“忙等”。
- 无条件传送方式
	**假设就绪，直接传送**——CPU**直接执行I/O指令**读写外设，**不检查设备状态**，假设外设**随时处于就绪状态**可立即接收或发送数据。
	
	**优点**：
	
	- **实现最简单**：无状态检测逻辑
	- **速度最快**：无额外开销
	- **实时性好**：精确控制传输时间
	
	**缺点**：
	
	- **可靠性差**：设备未就绪会导致数据丢失
	- **应用受限**：只适用于极简单外设
	- **无错误处理**：无法检测传输错误
- 程序查询方式

	**主动轮询，确认再传**——CPU**循环查询设备状态寄存器**，**确认设备就绪后**才执行数据传送，否则**持续占用CPU等待**。
	
	**优点**：
	
	- **实现相对简单**：逻辑清晰，易于理解
	- **可靠性提高**：避免设备未就绪时传输
	- **灵活性好**：可处理多种状态和错误
	- **无硬件依赖**：纯软件实现，无需DMA等硬件
	    
	**缺点**：
	
	- **CPU效率极低**：大量时间浪费在忙等待
	- **实时性差**：无法及时响应其他任务
	- **可扩展性差**：多个设备时查询顺序固定
	- **响应延迟**：轮询间隔导致响应延迟

### 3.3 中断方式

- 利用中断方式完成数据的输入输出过程-**被动响应，异步处理**
	- CPU**正常执行程序**，外设**准备就绪时主动中断**CPU，CPU**暂停当前任务**，**转去执行中断服务程序**处理数据I/O，完成后**返回原程序继续执行**。
	- **原理**：CPU启动I/O操作后，就可以转去执行其他任务。当I/O设备完成数据准备或传输后，会向CPU发出一个**硬件中断**信号。CPU收到中断后，暂停当前工作，执行一个简短的**中断服务程序**来处理这个I/O事件（例如，将数据从设备缓冲区读入内存）。
	- **优点**：解放了CPU，使其在等待I/O时能执行其他计算任务。
	- **缺点**：对于高速设备或大量数据传输，频繁的中断仍然会消耗大量CPU时间。
- 中断处理方法
	- 多终端信号线法（专用线路法）
		- 每个中断源分配独立的信号线连接到CPU，CPU通过物理线路直接识别中断来源。
		- 优点：
			响应最快：无需查询，硬件直接识别
			优先级硬件固定：线路连接顺序决定优先级
			实现简单：逻辑清晰，易于理解
			并发处理方便：可同时响应多个中断
		- 缺点：
			引脚资源浪费：每个中断需单独引脚，扩展性差
			硬件复杂度高：多线路增加布线复杂度
			灵活性差：优先级固定，无法动态调整
			成本较高：占用大量CPU引脚和PCB空间
	- 中断软件查询法（轮询法）
		 - 所有中断源共享同一中断请求线，CPU响应后软件依次查询每个设备的状态寄存器确定中断源。
		- 优点：
			硬件最简单：只需一根中断请求线
			成本最低：节省引脚和线路资源
			灵活性高：软件可动态调整查询顺序和优先级
			易于扩展：增加设备只需扩展查询代码
		- 缺点：
			响应速度慢：需要逐个查询，延迟大
			CPU开销大：查询过程消耗CPU时间
			实时性差：低优先级中断可能被长时间阻塞
			效率低下：即使无中断也要执行查询代码
	- 菊花链法（串行优先级法）
		- 中断源串联连接，中断响应信号沿链式传递，第一个响应的设备阻塞后续设备。
		- 优点：
			硬件优先级：位置决定优先级，固定可靠
			节省资源：共享中断请求线和响应线
			响应速度中等：比软件查询快
			扩展方便：可串联多个设备
		- 缺点：
			优先级固定：设备位置决定，无法动态调整
			可靠性问题：链中任一设备故障影响后续所有设备
			延迟累积：中断响应信号需传递整个链
			灵活性差：添加/移除设备需重新布线
	- 总线仲裁法（中断控制器法）
		- 专用中断控制器集中管理所有中断源，进行优先级仲裁后向CPU发送单个中断请求。
		- 优点：
			灵活优先级：可编程设置和动态调整
			CPU负担轻：仲裁由专用硬件完成
			功能丰富：支持嵌套、屏蔽、向量化等
			扩展性好：标准接口，易于扩展
		- 缺点：
			硬件成本增加：需要额外中断控制器芯片
			响应延迟：增加一级仲裁环节
			配置复杂：需要初始化编程
			单点故障风险：控制器故障导致所有中断失效
	- 中断向量表法（向量中断）
		- 每个中断源对应唯一向量号，中断发生时设备直接提供向量号，CPU查表跳转到相应服务程序。
		- 优点：
			响应速度最快：直接跳转，无需查询或仲裁
			灵活性最高：向量号可编程映射
			支持丰富特性：可轻松实现优先级、嵌套等
			软件接口清晰：向量表统一管理所有中断
		- 缺点：
			硬件复杂度高：需要向量号生成和传输机制
			资源需求大：需要向量表存储空间
			配置管理复杂：向量表需正确初始化和维护
			安全性考虑：需要保护向量表不被篡改
- 中断优先级控制
	- 多中断源系统中，对服务的要求紧迫程度不同，所以需要对紧迫的中断源分配最高优先级
	- 当不同优先级的多个中断源同时提出中断请求时，应优先响应最高优先级的
	- 当CPU 正在对 某一个中断源服务是，由比他还高优先级的中断请求，CPU应暂时中断正在执行的中断服务程序，转而执行优先级高的，这种情况叫中断嵌套，即一个重点服务中嵌套这另一个中断服务程序
### 3.4 直接存储器存取方式

- **定义**：计算机系统中，允许外部设备（如硬盘、网卡、显卡）直接与内存交换数据，**无需CPU介入**的技术。
- **原理**：由专门的**DMA控制器**接管整个数据块的传输过程。
	1. CPU向DMA控制器发送命令（如：读/写、内存起始地址、数据块大小）。
	2. DMA控制器直接控制I/O设备，并与内存进行数据交换。
	3. 整个数据块传输完成后，DMA控制器向CPU发出一个**中断**通知。 
- **优点**：将CPU从繁重的数据搬运工作中彻底解放出来，仅在开始和结束时介入。这是现代计算机处理大批量I/O数据（如磁盘读写）的标准方式。
- **作用**：大幅减轻CPU负担，提升数据传输效率。
- **应用**：硬盘读写、视频/音频数据流传输、网络数据包处理等。

### 3.5 输入输出处理机（IOP）

- **定义** ：它是一个**专用处理器**，专门负责处理系统的所有输入输出操作。它是 **通道** 概念的现代和更通用化的实现。更高级、更智能的I/O方式，主要用于大型机系统。
- **结构与工作方式**：
	- IOP 与 CPU、内存、I/O设备共同构成一个更强大的系统架构：
	- **CPU（中央处理器）**：负责核心计算和系统管理。
	- **IOP**：作为CPU的“助手”，专门管理I/O。
	- **内存**：CPU和IOP共享内存进行通信。
- **原理**：**通道**是一个专用处理器，它有自己的指令集（通道命令字CCW），可以执行一个由多个I/O操作组成的**通道程序**。
- **与DMA的区别**：DMA控制器本质上是一个“数据搬运工”，而通道是一个“可编程的I/O协处理器”，能处理更复杂的I/O控制逻辑，管理多个设备。
- **优点**：进一步将I/O系统的管理和控制功能从CPU卸载，使CPU和I/O系统的并行度更高。

### 3.6 总结：从CPU直接控制到IOP的演进

| 处理方式        | 核心思想            | CPU参与度    | 适用场景             |
| ----------- | --------------- | --------- | ---------------- |
| **程序控制I/O** | CPU轮询，全程控制      | 100%，忙等   | 简单、低速设备（早期系统）    |
| **中断驱动I/O** | 设备就绪后通知CPU      | 每次传输前后介入  | 中低速、交互式设备（键盘、鼠标） |
| **DMA**     | 专用硬件搬运数据块       | 仅开始和结束时介入 | 高速、块设备（磁盘、网卡）    |
| **IOP/通道**  | 专用处理器管理整个I/O子系统 | 仅高级调度和通信  | 高性能计算、大型服务器系统    |
## 4. 总线结构

> 计算机的 **总线结构** 是计算机各部件（CPU、内存、I/O设备）之间传递信息的公共通道，是计算机系统的“骨架”和“高速公路系统”。它的设计直接关系到系统的性能、成本和可扩展性。
### 4.1 什么是总线？

**总线** 是一组由导线构成的、能够传输数据、地址和控制信号的公共通信路径。它包含：

1. **数据总线**：双向传输数据，宽度（位数）决定了CPU与外界一次能交换的数据量（如32位、64位）。
2. **地址总线**：单向（从CPU发出），用于指定要访问的内存单元或I/O端口的地址，宽度决定了CPU的寻址能力（如32位地址总线可寻址4GB空间）。
3. **控制总线**：传输各种控制信号（如读写、中断请求、时钟、复位等），方向各异。

**关键特性：共享性**。任何时刻，通常只能有一对部件（一个发送者，一个接收者）使用总线进行通信。

### 4.2 总线结构的主要类型（演进）

总线结构随着计算机发展不断演进，主要分为以下几类：
#### 4.2.1 单总线结构
- **描述**：系统中所有部件（CPU、内存、I/O设备）都连接到同一组总线上。
- **优点**：
    - 结构简单，成本低。
    - 易于添加新设备，扩展性好。
- **缺点**：
    - **总线竞争严重**：所有设备共用一条路，带宽成为瓶颈。
    - **性能差**：高速的CPU和内存访问会被低速的I/O操作阻塞。
- **适用**：早期微型机、简单嵌入式系统。
#### 4.2.2 双总线结构

> 为了缓解单总线瓶颈，引入了存储总线，将高速的CPU-内存通信与低速的I/O通信分离。

**A. 以CPU为中心的双总线结构**
- **描述**：一条是CPU与内存专用的 **存储总线**，另一条是连接CPU与I/O设备的 **I/O总线**。
- **缺点**：所有I/O与内存交换数据都必须经过CPU，仍然消耗CPU资源。

**B. 以存储器为中心的双总线结构**
- **描述**：一条是CPU与内存专用的 **存储总线**，另一条是内存与I/O设备直接通信的 **系统总线**。
- **优点**：I/O设备可以直接与内存交换数据（DMA），无需CPU介入，解放了CPU。
- **典型代表**：经典的 **北桥-南桥** 芯片组架构的前身。
#### 4.2.3 三总线结构

> 这是现代个人计算机的主流架构，在双总线基础上进一步细分。

- **描述**：
    1. **CPU-内存总线**：或称**前端总线**，连接CPU和北桥/内存控制器，速度最快。
    2. **I/O总线**：连接南桥和各种中低速外设（如PCI总线）。
    3. **扩展总线**：连接更具体、更低速的设备（如ISA总线、LPC总线）。
- **芯片组核心**：
    - **北桥**：负责高速通信（CPU、内存、显卡）。
    - **南桥**：负责中低速I/O（硬盘、USB、声卡、网卡等）。
- **图示**：
	- **优点**：层次分明，不同速度的设备使用不同总线，避免相互干扰，系统性能高。
	- **缺点**：结构复杂，北桥成为高速设备间的瓶颈。
#### 4.2.4 多总线层次结构

> 这是当代和未来计算机的发展方向，以**点对点串行总线**（特别是 **PCI Express**）为代表，取代了传统的**并行共享总线**。

- **核心思想**：取消“共享”的概念，为需要高带宽的设备（如显卡、SSD）提供**独占的、点对点的双向通道**。
- **描述**：
    - CPU内部集成**内存控制器**，直接与内存通信，取消了北桥。
    - 采用 **PCIe** 交换架构：一个**根复合体** 连接多个PCIe设备，每个设备都有自己独立的“车道”。
- **优点**：
    - **超高带宽**：串行高速传输，可灵活扩展通道数（x1, x4, x8, x16）。
    - **无竞争**：每个设备独享通道带宽。
    - **延迟低**：点对点连接。
    - **结构灵活**：支持热插拔，扩展性强。
- **适用**：所有现代PC、工作站、服务器。


### 4.3 常见总线

#### 4.3.1 系统扩展总线（插卡用）
 
 1. **ISA - 工业标准架构**
	- **做什么**：IBM PC/AT的16位扩展总线标准
	- **特点**：8MHz，16位，黑色长插槽，需手动配置跳线
	- **用途**：显卡、声卡、网卡、多功能卡
	- **现状**：完全淘汰，仅存于博物馆
2. **EISA - 扩展工业标准架构**
	- **做什么**：32位ISA扩展，对抗IBM的MCA
	- **特点**：兼容ISA卡，32位，支持总线主控
	- **用途**：高端服务器和工作站
	- **现状**：被PCI取代
3. **PCI - 外设组件互连**
	- **做什么**：取代ISA的32/64位并行总线
	- **特点**：33/66MHz，共享总线，即插即用，白色插槽
	- **用途**：声卡、网卡、早期显卡、各种功能卡
	- **现状**：被PCIe取代，但仍有低速设备使用
4. **PCI Express - PCIe**
	- **做什么**：现代高速串行点对点总线
	- **特点**：点对点、全双工、可配置通道(x1,x4,x8,x16,x32)
	- **用途**：显卡、NVMe SSD、高速网卡、专业采集卡
	- **版本**：PCIe 1.0→2.0→3.0→4.0→5.0→6.0（带宽翻倍增长）
	- **现状**：绝对主流，不断演进
#### 4.3.2 系统内部总线

5. **FSB - 前端总线**
	- **做什么**：连接老式CPU和北桥
	- **特点**：CPU与系统通信的命脉
	- **速度**：400MHz→800MHz→1333MHz等
	- **现状**：完全淘汰，现代CPU集成内存控制器
6. **其他内部总线**
	- **QPI**（英特尔）和 **HyperTransport**（AMD）：
		- **做什么**：CPU之间或CPU与芯片组的超高速连接
		- **特点**：点对点、低延迟、高带宽
	- **DMI**（直接媒体接口）：
		- **做什么**：Intel CPU与PCH芯片组连接
		- **特点**：替代老的南北桥连接
	- **Infinity Fabric**：
		- **做什么**：AMD Zen架构的内部互连总线
		- **特点**：统一CPU内部和CPU间的通信
#### 4.3.3 存储总线/接口

7. **SCSI - 小型计算机系统接口**
	- **做什么**：高性能并行存储接口
	- **特点**：一条总线可接多设备（8或16个）、需终结器
	- **版本**：SCSI-1→Fast SCSI→Ultra SCSI→Ultra320 SCSI
	- **用途**：服务器硬盘、磁带机、扫描仪
	- **现状**：被SAS（串行SCSI）取代
8. **PATA/IDE**
	- **做什么**：早期个人电脑硬盘接口
	- **特点**：宽排线，主从设备设置，40/80针
	- **速度**：ATA-33/66/100/133
	- **现状**：完全被SATA取代
9. **SATA - 串行ATA**
	- **做什么**：取代PATA的串行硬盘接口
	- **特点**：细长线缆，支持热插拔
	- **版本**：SATA 1.0(1.5Gb/s)→2.0(3Gb/s)→3.0(6Gb/s)
	- **用途**：机械硬盘、SATA固态硬盘、光驱
10. **SAS - 串行连接SCSI**
	- **做什么**：企业级存储接口
	- **特点**：兼容SATA设备、双端口冗余、可靠性高
	- **现状**：企业服务器和存储系统主流
11. **NVMe**
	- **做什么**：通过PCIe访问固态硬盘的协议
	- **特点**：超低延迟、超高队列深度
	- **接口**：M.2、U.2、PCIe插卡式
	- **现状**：高性能固态硬盘标准
#### 4.3.4 外部设备总线

12. **RS-232C**
	- **做什么**：串行通信接口
	- **特点**：9针或25针，异步通信，距离15米
	- **用途**：调制解调器、终端、串口鼠标、工业控制
	- **现状**：被USB取代，但仍是调试接口（Console口）
13. **USB - 通用串行总线**
	- **做什么**：外部设备通用接口
	- **版本演进**：
	    - USB 1.1：12Mbps（全速）
	    - USB 2.0：480Mbps（高速）
	    - USB 3.x：5-20Gbps（超高速）
	    - USB4：40Gbps（与雷电3/4融合）
	- **接口类型**：Type-A、Type-B、Mini、Micro、Type-C
	- **现状**：全球最普及的外部接口
14. **IEEE-1394 - 火线**
	- **做什么**：苹果主导的高速串行总线
	- **特点**：对等网络、高功率供电、等时传输
	- **版本**：FireWire 400(400Mbps)、800(800Mbps)、S3200(3.2Gbps)
	- **用途**：数码摄像机、外置硬盘、音频设备
	- **现状**：被USB 3.0+淘汰
15. **Thunderbolt - 雷电**
	- **做什么**：英特尔和苹果的超高速全能接口
	- **特点**：融合PCIe和DisplayPort，单线缆解决数据、视频、供电
	- **版本**：雷电1/2(20Gbps)、雷电3/4(40Gbps)
	- **现状**：高端笔记本和工作站的主流接口
#### 4.3.5 视频总线

16. **AGP - 加速图形端口**
	- **做什么**：显卡专用接口
	- **特点**：基于PCI但专门优化图形传输
	- **版本**：AGP 1x→2x→4x→8x
	- **现状**：被PCIe x16取代
17. **DisplayPort**
	- **做什么**：视频电子标准协会制定的数字视频接口
	- **特点**：高带宽、支持多流传输、免费授权
	- **版本**：DP 1.2→1.3→1.4→2.0→2.1
	- **用途**：电脑显示器、专业视频领域
18. **HDMI - 高清晰度多媒体接口**
	- **做什么**：消费电子领域音视频接口
	- **特点**：音视频同传、消费电子标准
	- **版本**：HDMI 1.4→2.0→2.1→2.1a
	- **用途**：电视、游戏机、影音设备
#### 4.3.6 网络总线

19. **Ethernet - 以太网**
	- **做什么**：局域网技术
	- **速度演进**：10Mbps→100Mbps→1Gbps→10Gbps→25/40/100Gbps
	- **接口**：RJ45、光纤、DAC线缆
	- **现状**：绝对主导的局域网技术
20. **Infiniband**
	- **做什么**：高性能计算和存储网络
	- **特点**：极低延迟、高带宽、远程直接内存访问
	- **用途**：超级计算机、数据中心、存储网络
21. **Fibre Channel**
	- **做什么**：存储区域网络
	- **特点**：专门为存储设计、高可靠性
	- **速度**：1G→2G→4G→8G→16G→32G FC
	- **用途**：企业级SAN存储
#### 4.3.7 移动设备总线

22. **SD/MMC**
	- **做什么**：移动设备存储卡接口
	- **版本**：SD→SDHC→SDXC→SDUC，速度等级Class 2/4/6/10、UHS-I/II/III
	- **用途**：相机、手机、平板电脑存储卡
23. **eMMC/UFS**
	- **做什么**：手机和平板电脑内置存储接口
	- **特点**：eMMC（嵌入式MMC，并行）、UFS（通用闪存存储，串行）
	- **现状**：UFS 3.0/4.0成为高端手机标准
24. **MIPI接口系列**
	- **做什么**：移动设备内部接口标准
	- **包含**：
	    - DSI：显示串行接口（屏幕）
	    - CSI：摄像头串行接口（摄像头）
	    - UniPro：通用芯片间互连
	    - 其他：SoundWire、RFFE等
#### 4.3.8 新兴/专用总线

25. **CXL - 计算快速链路**
	- **做什么**：CPU与加速器、内存之间的高速缓存一致性互连
	- **特点**：基于PCIe 5.0/6.0物理层，增加缓存一致性协议
	- **用途**：AI加速器、内存池化、异构计算
26. **Gen-Z**
	- **做什么**：内存语义互连
	- **特点**：以内存为中心、高带宽、低延迟
	- **用途**：下一代数据中心互连
27. **CCIX - 加速器缓存一致性互连**
	- **做什么**：加速器缓存一致性标准
	- **特点**：多厂商支持、开放标准
	- **用途**：FPGA、AI加速器互连

#### 汇总表：按领域分类

| 领域       | 主流总线/接口         | 特点             | 现状         |
| -------- | --------------- | -------------- | ---------- |
| **扩展总线** | PCIe            | 点对点、可扩展、高速     | 绝对主流       |
| **存储接口** | SATA/NVMe       | SATA普及、NVMe高性能 | 并存         |
| **外部接口** | USB/雷电          | USB通用、雷电高性能    | USB普及、雷电高端 |
| **视频接口** | HDMI/DP         | HDMI消费、DP专业    | 并存，各有所长    |
| **移动**   | UFS/MIPI        | 低功耗、高性能        | 移动设备标准     |
| **高性能**  | Infiniband/CXL  | 极低延迟、高带宽       | HPC/数据中心   |
#### 演进趋势总结

1. **从并行到串行**：PCI→PCIe，PATA→SATA，并行SCSI→串行SAS
2. **从共享到点对点**：共享总线→交换网络
3. **从专用到通用**：专用接口→USB统一
4. **从外部到内部集成**：北桥功能集成到CPU
5. **从单一功能到融合**：雷电融合数据、视频、供电
6. **语义演进**：从I/O语义到内存语义（CXL、Gen-Z）