---
date: 2025-12-28 18:31:03
title: 计算机体系结构
permalink: /pages/535598
categories:
  - 第1章 计算机系统知识
tags:
  - 第1章 计算机系统知识
coverImg: /backgrounds/212.jpg
---
# 计算机体系结构

| **层面**                        | **定义**                              | **关注点**   | **举例**              |
| ----------------------------- | ----------------------------------- | --------- | ------------------- |
| **体系结构**  <br>（Architecture）  | **程序员可见的抽象**  <br>指令集架构（ISA）定义"做什么" | 功能特性、编程模型 | x86-64、ARMv8、RISC-V |
| **组成/组织**  <br>（Organization） | **硬件组件及其连接**  <br>实现体系结构的方式 决定"怎么做" | 内部结构、数据通路 | 流水线深度、缓存层次、总线结构     |
| **实现**  <br>（Implementation）  | **物理实现细节** 解决"用什么做"                 | 物理设计、制造工艺 | 晶体管布局、时钟频率、功耗       |
## 1. 计算机体系结构的发展

### 1.1 计算机体系结构发展概述
#### **1. 早期发展阶段（1940s-1960s）** -- 奠定基础的时代

- **冯·诺依曼体系结构**（1945）
    
    - 存储程序概念
	    - 程序和数据存储在同一存储器
		- 指令可像数据一样被修改
		- 实现真正的通用计算
    - 五大部件：运算器、控制器、存储器、输入设备、输出设备
    - 顺序执行指令
	    - 取指令 → 译码 → 执行 → 写回
        
- **电子管→晶体管→集成电路**的硬件演进
    
#### **2. 经典体系结构时期（1970s-1980s）** -- CISC的黄金时代

- **CISC（复杂指令集计算机）** 
    
    - 让硬件完成复杂功能，简化编译器设计
    - 丰富的指令集
	    - 数百条指令
		- 复杂寻址方式
		- 可变长度指令
    - 微程序控制
	    - 复杂指令 → 微程序ROM → 微指令序列 → 控制信号
    - 代表：x86架构
        
- **流水线技术**的出现
- **缓存（Cache）** 的引入
	- 解决CPU与主存速度不匹配

#### **3. RISC革命（1980s-1990s）** -- 精简化的胜利

- **背景问题**（John Cocke，1970s IBM研究）：
	- 20%的简单指令占80%的使用时间
	- 复杂指令很少使用但增加硬件复杂度
- **精简指令集计算机**
    
    - 简化指令集
	    - 只保留高频使用的指令
		- 指令长度固定（通常32位）
		- 简化寻址方式
	- **加载/存储架构**：
		```
		RISC风格（ARM/MIPS）
		LDR R1, [`R2`]     ; 加载到寄存器
		ADD R3, R1, R4   ; 寄存器运算
		STR R3, [R5]     ; 存回内存
		
		对比CISC（x86）
		ADD [AX], [BX]   ; 直接内存操作
		```
	 
	 - 硬布线控制	
		- 取代微码控制
		- 提高指令执行速度
	 - 流水线深度优化
	 - 代表：ARM、MIPS、SPARC
        
- **超标量（Superscalar）** 架构 ： 单个时钟周期发射多条指令
- **乱序执行（Out-of-Order Execution）** ： 按序取指 → 寄存器重命名 → 乱序执行 → 按序提交
	- **优势**：
		- 克服数据依赖限制
		- 提高功能单元利用率
    

#### **4. 并行与多核时代（2000s-2010s）** -- 并行化的必然选择

- **单核性能极限**

```
	1. 功耗墙（Power Wall）：
	   Pentium 4：130W → 无法继续提高频率
	   
	2. 存储墙（Memory Wall）：
	   CPU速度 ↑ 10倍/10年
	   内存速度 ↑ 1.1倍/10年
	
	3. ILP墙（指令级并行墙）：
	   程序固有并行度有限
	   超标量收益递减
```

- **多核处理器**成为主流
    
    - 解决功耗墙问题 
		- 功耗效率：
		- 单核：频率↑ → 功耗∝频率³
		- 多核：频率不变，核心数↑ → 性能线性增长
    - 片上多处理器（CMP）
	    - 早期：多个独立芯片封装
	    - 现在：单芯片集成多个完整核心
	    - **共享资源设计**：

			```
					┌─────────┬─────────┬─────────┐
					│  Core 1 │  Core 2 │  Core 3 │
					├─────────┴─────────┴─────────┤
					│        共享L3缓存            │
					├─────────────────────────────┤
					│       内存控制器/互连         │
					└─────────────────────────────┘
			```
- **SIMD扩展**（MMX、SSE、AVX）
    
- **异构计算**兴起
    
    - CPU + GPU协同
	    - CPU：复杂控制流，低并行度任务
	    - GPU：简单控制流，高并行度任务
	- **NVIDIA CUDA**（2007）：
		- 通用GPU计算框架
		- 开启GPGPU时代
	- **APU概念**（AMD Fusion，2011）：
		- CPU + GPU集成在同一芯片
		- 共享内存，减少数据拷贝
        
#### **5. 现代发展趋势（2020s-现在）** -- 专用化与智能化

- **领域专用架构（DSA）**
    
    - AI加速器（TPU、NPU）
    - 可重构计算
	    - **FPGA动态重构**
		- 运行时根据任务调整硬件
        
- **存算一体**
    
    - **传统冯·诺依曼瓶颈**：
	    - CPU计算1次：约1pJ（皮焦）
		- 从内存取数据：约100pJ
		- 能耗比：1:100
    - 减少数据搬运
    - **近内存计算**
	    - 计算单元靠近内存
		- HBM（高带宽内存）+ 计算逻辑
	- **内存内计算**：
	    - 利用内存单元本身进行计算
	    - 电阻式内存（ReRAM）、相变内存（PCM）
        
- **量子计算架构**
	- 叠加态：同时表示0和1
	- 纠缠态：量子位相互关联
- **神经形态计算**
	- **事件驱动**：有事件才处理
	- **异步通信**：无全局时钟
	- **存算一体**：突触存储权重并计算
- **Chiplet与先进封装**
	- 传统：单芯片集成所有功能
	- Chiplet：多个小芯片（Chiplet）通过先进封装集成
- **安全架构强化**
	- **硬件安全特性**：
	- **Intel SGX**：可信执行环境
	- **ARM TrustZone**：硬件隔离安全区
	- **内存安全**：防止缓冲区溢出等攻击

#### 发展总结

#### 技术演进图谱

``` text

时间轴：    1940s     1950s     1960s     1970s     1980s     1990s     2000s     2010s     2020s
          ────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┼────
硬件：    电子管 → 晶体管 → IC → LSI → VLSI → 微处理器 → 多核 → 众核 → 异构 → Chiplet
          ────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┼────
架构：    冯·诺依曼 → 微程序 → CISC主导 → RISC革命 → 超标量 → 多核 → GPU计算 → DSA → 存算一体
          ────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┼────
并行：     无     →    无     →  向量机  →  流水线  →超标量 → 乱序执行 → 多线程 → 众核 → 异构并行
          ────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┼────
性能：  1 OPS → 10K OPS → 1M OPS → 10M OPS → 1G OPS → 10G OPS → 1T OPS → 10T OPS → 1P OPS

```
#### 关键趋势总结

1. **抽象层次不断提升**：
    
    晶体管 → 逻辑门 → 功能单元 → 处理器核心 → 多核系统 → 计算集群
    
2. **设计哲学演变**：
    
    简单硬件（早期）→ 复杂硬件（CISC）→ 简单硬件+智能编译（RISC） → 并行硬件（多核）→ 专用硬件（DSA）
    
3. **性能驱动力转变**：
    
    频率提升 → 指令级并行 → 数据级并行 → 线程级并行 → 任务级并行
    
4. **未来方向**：
    
    - **专用化**：针对特定负载优化
    - **异构化**：多种计算单元协同
    - **智能化**：硬件自适应调整
    - **能效优先**：性能/瓦特成为关键指标

### 1.2 计算机体系结构的分类

#### 1. 宏观分类（按处理机数量）

##### **1. 单处理机系统**

- **特点**：单个CPU执行指令
- **分类**：
    - 单用户系统：**一人一机，独占所有** —— 同一时间只有一个用户独占整个计算机系统的所有资源。
    - 多道程序系统：**一芯多用，内存分工** —— 单个CPU通过内存中同时驻留多个程序并切换执行，**提高资源利用率**。
    - 分时系统：**多人共享，轮转服务** —— 多个用户通过终端共享同一台计算机，CPU采用**时间片轮转**方式快速切换，为每个用户提供**交互式体验**。
##### **2. 多处理机系统**

- **对称多处理（SMP）** ：**对等协作，资源共享**
    
    - 所有处理器地位相同、能力对等
    - **共享统一的内存和I/O资源**
    - **单一操作系统统一管理和调度**
        
- **非对称多处理（AMP）** : **主从分工，专事专办**

	> 一个主处理器负责系统控制和任务分配，多个从处理器**专门处理特定类型任务**（如I/O处理、浮点运算等）

    - 主从结构
    - 专用处理器分工
##### **3. 多计算机系统**

- **集群系统（Cluster）**：**独立自治，消息互联**

	> 由**多个独立计算机**组成的**松耦合系统**，各计算机拥有**独立的内存空间**，通过**消息传递**方式在网络上进行通信协作。

    - 松耦合系统
    - 各自独立内存
    - 消息传递通信
        
- **大规模并行处理（MPP）**：**千芯互联，高速协作**

	> 由**数千个处理器**通过**专用高速互连网络**紧密连接，形成单一、统一的高性能计算系统。
	
    - 专用高速互连
    - 数千个处理器
##### **4. 分布式系统**：**地理分散，透明共享**

- **特点**：

    > 将**地理分布**的计算机资源通过网络连接，为用户提供**透明访问**的统一服务，实现**资源共享**和**高可用性**。

	- 地理分布
    - 透明访问
    - 资源共享
    - 高可用性
##### **5. 发展趋势**

> 单机 → SMP → 集群 → 云 → 边缘计算

#### 2.微观分类（按并行程度）

##### 1. Flynn 分类法（最经典）

基于**指令流**和**数据流**的数量

|**类型**|**指令流**|**数据流**|**特点**|**代表**|
|---|---|---|---|---|
|**SISD**  <br>单指令单数据|1|1|传统串行计算机|早期计算机|
|**SIMD**  <br>单指令多数据|1|多|数据级并行|GPU、向量机|
|**MISD**  <br>多指令单数据|多|1|理论上存在  <br>实际很少使用|容错系统|
|**MIMD**  <br>多指令多数据|多|多|任务级并行|多核CPU、集群|
##### 2. 按并行粒度分类

```
	 宏观并行
	    ↓
	┌─────────────────┐
	│   进程级并行     │ ← 粗粒度
	├─────────────────┤
	│   线程级并行     │ ← 中粒度
	├─────────────────┤
	│   指令级并行     │ ← 细粒度
	├─────────────────┤
	│   数据级并行     │ ← 细粒度
	└─────────────────┘
```

**详细展开**：
 
**A. 线程/进程级并行（粗粒度）**

```
	进程1：┌───┬───┬───┐
	进程2：   └───┬───┬───┐
	进程3：       └───┬───┘
	      时间→
```
- **多道程序设计**
- **多任务处理**
- **多线程编程**

**B. 指令级并行（ILP，细粒度）**

```
	传统：取指 → 译码 → 执行 → 访存 → 写回
	流水线：IF → ID → EX → MEM → WB
	         IF → ID → EX → MEM → WB
	              IF → ID → EX → MEM → WB
```

**技术实现**：

1. **流水线（Pipeline）**
2. **超标量（Superscalar）**
    
```
    时钟周期1：指令A 指令B 指令C
    时钟周期2：指令D 指令E 指令F
```
    
3. **超长指令字（VLIW）**
4. **乱序执行（OoOE）**

 **C. 数据级并行（DLP，细粒度）**

- **向量处理** 
- **SIMD扩展**

**D. 任务级并行（TLP，中粒度）**

- **多核处理器**
 
```
    Core1：┌─────任务A─────┐
    Core2：┌─────任务B─────┐
    Core3：┌─────任务C─────┐
```
    
- **同时多线程（SMT）**
    
    - Intel Hyper-Threading
    - 单个核心"虚拟"为多个逻辑处理器
##### 3. 按内存架构分类

**A. 共享内存系统**

```
     ┌──────┐  ┌──────┐  ┌──────┐
     │ CPU1 │  │ CPU2 │  │ CPU3 │
     └──────┘  └──────┘  └──────┘
          ↓         ↓         ↓
     ┌──────────────────────────┐
     │       共享内存            │
     └──────────────────────────┘
```

- **UMA（均匀内存访问）**
    
    - 访问时间一致
    - SMP系统
        
- **NUMA（非均匀内存访问）**
    
    - 访问时间不一致
    - 现代多处理器系统

**B. 分布式内存系统**

```
    ┌──────┐      ┌──────┐      ┌──────┐
	│ CPU+ │      │ CPU+ │      │ CPU+ │
	│内存1 │      │内存2 │      │内存3 │
	└──────┘      └──────┘      └──────┘
	     ↓消息传递        ↓消息传递
	    网络互连
```
##### 4. 现代混合架构

**A. CPU+GPU异构系统**

```
	┌───────────────────────┐
	│        CPU（控制）     │
	│  多核，通用计算         │
	└───────────┬───────────┘
	            ↓ PCIe
	┌───────────────────────┐
	│        GPU（计算）     │
	│  数千核心，数据并行     │
	└───────────────────────┘
```

**B. 存算一体架构**

	传统：CPU → 内存总线 → DRAM → 处理 → 返回
	存算：在内存内部直接计算

#### 3.分类的总结与趋势

##### 1. 发展规律

- **从串行到并行**
- **从同构到异构**
- **从通用到专用**
- **从计算中心到存算一体**
##### 2. 分类关系总结

```
	宏观（系统级）                 微观（处理器级）
	    ↓                               ↓
	┌──────────────┐              ┌──────────────┐
	│ 单处理机系统  │              │    SISD      │
	├──────────────┤              ├──────────────┤
	│ 多处理机系统  │ ← 对应 →     │ SIMD/MIMD    │
	├──────────────┤              ├──────────────┤
	│ 多计算机系统  │              │ 数据/任务并行 │
	└──────────────┘              └──────────────┘
```
##### 3. 未来方向

1. **专用化**：AI芯片、量子芯片
2. **集成化**：Chiplet、3D堆叠
3. **智能化**：自适应架构
4. **能效优先**：每瓦性能优化
5. **软硬件协同**：编译器感知架构
### 1.3 指令系统

> 一个处理器支持的指令和指令的字节级编码称为其指令集体系结构（ISA） 
#### **按复杂度**：

- **CISC**：**硬件复杂化，指令多功能化**
- **RISC**：**硬件精简化，指令单功能化**
#### **按存储模型**：

- **堆栈型**：**操作数在栈顶，隐含寻址**
- **累加器型**：**专用累加器，操作中心化**
- **寄存器-存储器型**：**内存直接操作，灵活高效**
- **加载/存储型**：**内存访问受限，寄存器为中心**
#### **现代趋势**：

- **模块化设计**：**基础+扩展，按需定制**
- **内部微码化**：**CISC外表，RISC内核**
- **向量化扩展**：**单指令多数据，并行加速**

### 1.4 阵列处理机、并行处理机、多处理机

1. **阵列处理机**：

> **数据并行，同步执行** —— 大量**相同处理单元**组成规则阵列，在**统一控制器**指挥下**同步执行同一条指令**处理不同数据。

2. **并行处理机**：

> **广义并行，指令多样** —— **多种并行计算系统**的总称，包括SIMD、MIMD等多种模式，强调**同时执行多个任务或操作**。

3. **多处理机**：

> **独立协作，异步并行** —— **多个完整处理器**通过互连网络连接，**独立执行不同程序或线程**，通过共享内存或消息传递协作。


## 2. 存储系统

### 2.1 存储器的层次结构

```
                  容量小、速度快、成本高
                  
      ┌─────────────────────────────────────┐
      │          CPU寄存器                   │ ← 1周期，~1KB
      └─────────────────────────────────────┘
                     ↓
      ┌─────────────────────────────────────┐
      │       高速缓存（Cache）              │
      │   L1: 2-4周期，32-64KB              │
      │   L2: 10-20周期，256KB-1MB          │
      │   L3: 30-50周期，8-32MB             │
      └─────────────────────────────────────┘
                     ↓
      ┌─────────────────────────────────────┐
      │         主存储器（RAM）              │ ← 100-300周期，8-128GB
      └─────────────────────────────────────┘
                     ↓
      ┌─────────────────────────────────────┐
      │      辅助存储器（磁盘/SSD）          │ ← 10^5-10^6周期，1-10TB
      └─────────────────────────────────────┘
                     ↓
      ┌─────────────────────────────────────┐
      │      三级存储器（磁带/光盘）          │ ← 离线，10-100TB+
      └─────────────────────────────────────┘
                      
                  容量大、速度慢、成本低
```

#### 层次化原理

- 局部性原理**
	
		```
		     // 时间局部性：最近访问的很快会再访问
		    for (i=0; i<100; i++) {
		        sum += array[i];  // sum被重复访问
		    }
		    
		    // 空间局部性：访问附近位置的可能性大
		    for (i=0; i<100; i++) {
		        array[i] = i;    // 连续内存访问
		    }
		```
		
- 访问频率与成本权衡
	
		性价比优化：CPU寄存器 > Cache > 内存 > SSD > HDD

### 2.2 存储器的分类

#### 1. 按所处位置分类

**内部存储器**：位于计算机主机内部，CPU可直接访问

- **寄存器**：CPU内部的极高速存储单元，容量最小，速度最快
- **高速缓存**：CPU与主存之间的高速缓冲，分为L1、L2、L3等层次
- **主存储器**：计算机的主要内存，即RAM，CPU通过总线直接访问

**外部存储器**：位于主机外部，需要通过I/O接口访问

- **磁盘存储器**：包括硬盘、软盘（已淘汰）
- **固态存储器**：SSD、U盘、存储卡
- **光存储器**：CD、DVD、蓝光光盘
- **磁带存储器**：用于数据备份和归档

#### 2. 按构成材料分类

 **半导体存储器**：基于半导体技术制造

- **易失性存储器**：断电后数据丢失
    
    - **SRAM**：静态随机存取存储器，6晶体管结构，速度快，用于Cache
    - **DRAM**：动态随机存取存储器，需定期刷新，用于主内存
        
- **非易失性存储器**：断电后数据保留
    
    - **ROM**：只读存储器，固件存储
    - **PROM**：可编程只读存储器，用户可编程一次
    - **EPROM**：可擦除可编程只读存储器，紫外线擦除
    - **EEPROM**：电可擦除可编程只读存储器
    - **Flash**：闪存，用于SSD、U盘

**磁表面存储器**：利用磁性材料存储

- **硬盘**：金属盘片表面涂覆磁性材料
- **磁带**：塑料带基涂覆磁性材料
    
**光存储器**：利用激光读写

- **CD**：压缩光盘，700MB容量
- **DVD**：数字多功能光盘，4.7-17GB
- **Blu-ray**：蓝光光盘，25-128GB
#### 3. 按工作方式分类
 
- **RAM**：读写存储器，包括SRAM和DRAM
- **ROM**：只读存储器，只能读取
    
#### 4. 按访问方式分类

- **按地址访问**
- **按内容访问**
#### 5. 按寻址方式分类

- **随机存储器**：可随机读写任意地址，访问任何地址的时间相同
- **顺序存储器**：必须按顺序访问，访问时间与数据位置相关
- **直接存储器**：先直接定位大致位置，再顺序访问
### 2.3 相联存储器 **

> **按内容寻址而非地址** —— 并行比较所有存储单元的内容，**直接找到匹配项**。

```
		          ┌─────────────────┐
			输入 → │ 比较逻辑阵列 │ ← 并行比较所有单元
		          ├─────────────────┤
		          │  存储单元阵列   │ ← 存储(key, value)对
		          ├─────────────────┤
			输出 → │ 匹配选择电路   │ ← 输出匹配结果
		          └─────────────────┘
```

#### **应用场景**

	1. 高速缓存（Cache的标签存储）
	2. 虚拟内存TLB（页表缓存）
	3. 数据库加速
	4. 网络路由表查找
	5. 模式匹配引擎
	6. 神经网络计算
#### **优缺点

	优点：
	1. 查找速度快（O(1)时间复杂度）
	2. 适合模糊匹配
	3. 硬件并行度高
	
	缺点：
	4. 硬件成本高（每个单元需比较器）
	5. 功耗较大
	6. 容量受限
	7. 制造工艺复杂
### 2.4 高速缓存

> 用来存放当前最活跃的程序和数据，特点是：位于 CPU 与主存之间，容量一般在几千字节和几兆字节之间，速度比主存快 5-10 倍，由快速半导体存储器构成，其内容是主存局部域的副本；
> 设计目标是 成本允许的条件下达到较高的命中率，是存储系统拥有最短的平均访问时间。

#### 组成

- 存储部分用来存放主存的部分拷贝信息
- 控制部分用来判断 CPU 要访问的信息是否在 Cache 存储中，
	- 若在即为命中。命中时直接对 Cache 存储器寻址；
	- 未命中时要按照替换原则决定主存的一块信息放到 Cache 存储器的哪一块里。
#### 地址映像方法

> 地址映像：CPU工作时，送出的时主存单元的地址，而应从 Cache 存储器中读写信息，这就需要将主存地址转换为 Cache 存储器的地址

1. 直接映射（Direct Mapped）
	1. 主存的块与 Cache 块的对应关系是固定的，主存的块只能放在 Cache 的相同块中
	2. 地址变换：只要主存区号与 Cache 中记录的主存区号相同就命中，块内地址就是主存地址中给的低位地址
	3. 优点是：地址变换简单
	4. 缺点是：灵活性差，不同区号中块号相同的块无法调入 Cache，导致有空着的块也不能用
2. 全相联映像
	1. 主存与 Cache 分成大小相同的块，允许主存的任一块都可以调入 Cache 的任意一块的空间中。
	2. 地址变换：利用主存地址高位表示的主存块号与 Cache 中所有单元中记录的主存块号比较，
		1. 相同即命中，单元编号就对应要访问 Cache 的块号，访问相应的存储单元
	3. 优点是：主存的块调入 Cache 的位置不受限制，十分灵活
	4. 缺点是：无法直接从主存块号中获取 Cache 的快好，变换比较复杂，速度慢
3. 组相联映像
	1. 前两种方法的折中，把块再分成组；
	2. 地址变换：通过直接映像方式找到组，通过全相联映像方式找到块。

#### 替换算法

> 目的就是使 Cahce 获得尽可能高的命中率

1. 随机替换算法：用随机数发生器产生一个要替换的块号，将块替换出去
2. 先进先出算法：最先进入信息块替换出去
3. 近期最少使用算法：将近期最少使用的信息块替换出去
4. 优化替换算法：先执行一次程序，统计块替换情况，根据这个情况，在第二次执行程序时便可以用最有效的方式替换

#### 性能分析

1. **性能指标**
	- **命中率**：Cache命中的访问次数占总访问次数的比例，是衡量Cache有效性的最重要指标。
	- **Miss率**：1 - 命中率，表示未命中的比例。
	- **平均访问时间**：综合命中时间和Miss代价的计算结果，反映整体性能。
	- **Miss代价**：处理一次Cache Miss所需的额外时间，包括访问下一级存储和可能的替换操作。
	- **带宽利用率**：Cache系统有效利用内存带宽的能力。

2. **Miss分类**
	- **强制性不命中**：第一次访问某数据必然发生的不命中，也称为冷启动不命中。只能通过预取技术减少。
	- **容量不命中**：由于Cache容量不足，无法容纳工作集导致的不命中。增加Cache容量或优化程序数据局部性可改善。
	- **冲突不命中**：由于映射冲突导致的不命中（直接映射和组相联中存在）。增加相联度或优化数据布局可减少。
	- **一致性不命中**：在多处理器系统中，由于Cache一致性维护导致的不命中。

3. **性能计算公式**
	- 平均访问时间 = 命中时间 + Miss率 × Miss代价
	- 对于多级Cache：AMAT = L1命中时间 + L1 Miss率 × (L2命中时间 + L2 Miss率 × (L3命中时间 + L3 Miss率 × 内存访问时间))

4. **性能影响因素**
	- **程序行为**：访问模式的空间局部性和时间局部性。
	- **Cache参数**：容量、块大小、相联度。
	- **替换算法**：影响容量和冲突不命中的处理效率。
	- **预取效果**：减少强制性不命中的能力。
	- **写策略**：写直达vs写回，影响写操作性能。
	- **多核影响**：共享Cache的竞争和一致性开销。

5. **优化技术**
	- **增大Cache容量**：减少容量不命中，但可能增加命中时间。
	- **优化块大小**：大块提高空间局部性但可能增加冲突和浪费。
	- **增加相联度**：减少冲突不命中但增加硬件成本和命中时间。
	- **使用Victim** **Cache**：存放最近被替换的块，减少冲突不命中的影响。
	- **预取技术**：主动加载可能使用的数据，减少强制性不命中。
	- **编译器优化**：重新组织数据布局和访问模式，提高局部性。

#### 多级 Cache

1. **L1 Cache**：最接近CPU，分为指令Cache和数据Cache（哈佛架构），容量小（32-64KB），速度最快（2-4周期延迟）。
2. **L2 Cache**：容量较大（256KB-1MB），统一存储指令和数据，延迟较高（10-20周期）。
3. **L3 Cache**：多核共享的大容量Cache（8-64MB），延迟更高（30-50周期），用于减少对主存的访问。
4. L4 Cache（可选）：某些系统使用eDRAM作为第四级Cache（128MB+），延迟约80-100周期。

### 2.5 虚拟存储器

> 对主存的一种抽象，使用虚拟地址（由 CPU 生成）的概念来访问主存，使用专门的内存管理单位将虚拟地址转换为物理地址后访问主存。
> 实质是对物理存储设备进行逻辑化处理，并将统一的逻辑视图呈现给用户，用户操作的是虚拟设备，无需关心底层的物理环境。

**核心机制**：

1. **地址空间虚拟化**：为每个进程提供独立的虚拟地址空间
2. **按需分页**：只加载需要的内存页到物理内存
3. **自动换页**：内存不足时将不常用的页交换到磁盘
4. **地址转换**：通过页表将虚拟地址映射到物理地址

**关键组件**：

- **页表**：记录虚拟页到物理页的映射关系
- **TLB**：缓存常用页表项，加速地址转换
- **MMU**：硬件内存管理单元，执行地址转换

**主要优势**：

- **透明扩展**：程序可使用超过物理内存的空间
- **内存隔离**：进程间互不干扰
- **简化管理**：程序看到连续空间，无需关心物理分布

**性能代价**：

- **地址转换开销**：需要查页表
- **缺页中断**：访问不在内存的页需要磁盘I/O
- **管理复杂性**：需要操作系统和硬件协同

### 2.6 外存储器

> 计算机外部存储设备，用于**长期保存数据**，**断电不丢失**，通过I/O接口与主机连接。

**硬盘**：

- **机械硬盘**：磁性盘片旋转，磁头读写数据
- **固态硬盘**：闪存芯片存储，无机械部件，速度快

**移动存储**：

- **U盘**：USB接口闪存设备
- **存储卡**：SD卡、TF卡等，用于相机手机

**光存储**：

- **光盘**：CD、DVD、蓝光光盘，激光读写

**磁带**：

- 顺序访问，容量大（可达数十TB）
- 主要用于数据备份和归档



### 2.7 磁盘阵列技术

> 将多个物理硬盘组合成**一个逻辑存储单元**，通过**数据分布**和**冗余**技术提高**性能**、**容量**和**可靠性**。

#### RAID各级别对比表

| **特性维度**  | **RAID 0**                         | **RAID 1**                           | **RAID 5**                        | **RAID 6**                   | **RAID 10**                         | **RAID 50**                      | **RAID 60**                        |
| --------- | ---------------------------------- | ------------------------------------ | --------------------------------- | ---------------------------- | ----------------------------------- | -------------------------------- | ---------------------------------- |
| **中文名称**  | 条带化                                | 镜像                                   | 带奇偶校验的条带化                         | 双重奇偶校验条带化                    | 镜像+条带化                              | RAID 5+RAID 0                    | RAID 6+RAID 0                      |
| **最小磁盘数** | 2                                  | 2                                    | 3                                 | 4                            | 4                                   | 6                                | 8                                  |
| **容量利用率** | 100%                               | 50%                                  | (n-1)/n                           | (n-2)/n                      | 50%                                 | (n-g)/n  <br>（g=组数）              | (n-2g)/n  <br>（g=组数）               |
| **容错能力**  | 无                                  | 允许1块磁盘故障                             | 允许1块磁盘故障                          | 允许2块磁盘故障                     | 每组镜像允许1块故障                          | 每组允许1块故障                         | 每组允许2块故障                           |
| **读性能**   | 优秀                                 | 优秀                                   | 优秀                                | 优秀                           | 优秀                                  | 优秀                               | 优秀                                 |
| **写性能**   | 优秀                                 | 一般                                   | 中等（有写惩罚）                          | 较差（双重写惩罚）                    | 优秀                                  | 中等                               | 较差                                 |
| **随机I/O** | 优秀                                 | 好                                    | 好                                 | 中等                           | 优秀                                  | 好                                | 中等                                 |
| **连续I/O** | 优秀                                 | 好                                    | 好                                 | 好                            | 优秀                                  | 优秀                               | 优秀                                 |
| **重建复杂度** | 不适用                                | 简单                                   | 中等                                | 复杂                           | 中等                                  | 中等                               | 复杂                                 |
| **重建时间**  | 不适用                                | 短                                    | 长                                 | 很长                           | 中等                                  | 长                                | 很长                                 |
| **成本效益**  | 高                                  | 低                                    | 高                                 | 中等                           | 低                                   | 中等                               | 中等                                 |
| **数据安全性** | 低                                  | 高                                    | 中等                                | 高                            | 高                                   | 高                                | 极高                                 |
| **典型应用**  | 视频编辑  <br>临时数据                     | 系统盘  <br>关键数据                        | 文件服务器  <br>通用存储                   | 关键数据存储  <br>高可用需求            | 数据库  <br>高性能应用                      | 中等规模  <br>企业存储                   | 大规模  <br>关键数据                      |
| **优缺点**   | **优点**：性能最佳，容量100%  <br>**缺点**：无冗余 | **优点**：可靠性高，读性能好  <br>**缺点**：容量浪费50% | **优点**：平衡性能与容量  <br>**缺点**：写性能有开销 | **优点**：双盘容错  <br>**缺点**：写开销大 | **优点**：性能+可靠性  <br>**缺点**：成本高，容量50% | **优点**：大容量+较好性能  <br>**缺点**：配置复杂 | **优点**：大容量+高容错  <br>**缺点**：配置复杂成本高 |

### 2.8 存储域网络

> **专用的高速网络**，将**存储设备**与**服务器**连接，提供**块级**的数据访问服务，构成一个**独立的存储资源池**。

## 3. 输入/输出技术

### 3.1 微型计算机中最常用的内存与接口编址方法

- 内存与接口地址独立编址方式：
	- **内存和I/O接口使用完全分离的地址空间**
	- CPU通过**不同的指令**（内存用MOV，I/O用IN/OUT）访问**不同的地址范围**，内存地址和I/O地址互不重叠、各自独立编址。

- 内存与接口地址统一编址方式
	- **内存和外设共享同一地址空间**
	- 内存地址和I/O端口地址**统一编号在同一线性地址空间内**，CPU**使用相同的访存指令**（如MOV、LDR）访问内存和外设寄存器，**无法通过地址值区分**访问的是内存还是I/O设备。

### 3.2 直接程序控制

#### 无条件传送方式

> **假设就绪，直接传送**——CPU**直接执行I/O指令**读写外设，**不检查设备状态**，假设外设**随时处于就绪状态**可立即接收或发送数据。

**优点**：

- **实现最简单**：无状态检测逻辑
- **速度最快**：无额外开销
- **实时性好**：精确控制传输时间

**缺点**：

- **可靠性差**：设备未就绪会导致数据丢失
- **应用受限**：只适用于极简单外设
- **无错误处理**：无法检测传输错误

#### 程序查询方式

> **主动轮询，确认再传**——CPU**循环查询设备状态寄存器**，**确认设备就绪后**才执行数据传送，否则**持续占用CPU等待**。

**优点**：

- **实现相对简单**：逻辑清晰，易于理解
- **可靠性提高**：避免设备未就绪时传输
- **灵活性好**：可处理多种状态和错误
- **无硬件依赖**：纯软件实现，无需DMA等硬件
    
**缺点**：

- **CPU效率极低**：大量时间浪费在忙等待
- **实时性差**：无法及时响应其他任务
- **可扩展性差**：多个设备时查询顺序固定
- **响应延迟**：轮询间隔导致响应延迟

### 3.3 中断方式

- 程序控制I/O方法-**CPU全程主导，软件决定流程**
	- CPU**通过执行I/O指令**直接控制数据传输的**每一个步骤**，**轮询设备状态**，**管理数据缓冲**，**处理错误情况**，整个过程完全在**程序逻辑控制下**进行。
- 利用中断方式完成数据的输入输出过程-**被动响应，异步处理**
	- CPU**正常执行程序**，外设**准备就绪时主动中断**CPU，CPU**暂停当前任务**，**转去执行中断服务程序**处理数据I/O，完成后**返回原程序继续执行**。

- 中断处理方法
	- 多终端信号线法（专用线路法）

		> 每个中断源分配独立的信号线连接到CPU，CPU通过物理线路直接识别中断来源。
		
		- 优点：
			响应最快：无需查询，硬件直接识别
			优先级硬件固定：线路连接顺序决定优先级
			实现简单：逻辑清晰，易于理解
			并发处理方便：可同时响应多个中断
		- 缺点：
			引脚资源浪费：每个中断需单独引脚，扩展性差
			硬件复杂度高：多线路增加布线复杂度
			灵活性差：优先级固定，无法动态调整
			成本较高：占用大量CPU引脚和PCB空间
	
	- 中断软件查询法（轮询法）
	
		>所有中断源共享同一中断请求线，CPU响应后软件依次查询每个设备的状态寄存器确定中断源。
		
		- 优点：
			硬件最简单：只需一根中断请求线
			成本最低：节省引脚和线路资源
			灵活性高：软件可动态调整查询顺序和优先级
			易于扩展：增加设备只需扩展查询代码
		- 缺点：
			响应速度慢：需要逐个查询，延迟大
			CPU开销大：查询过程消耗CPU时间
			实时性差：低优先级中断可能被长时间阻塞
			效率低下：即使无中断也要执行查询代码
	
	- 菊花链法（串行优先级法）
	
		> 中断源串联连接，中断响应信号沿链式传递，第一个响应的设备阻塞后续设备。
	
		- 优点：
			硬件优先级：位置决定优先级，固定可靠
			节省资源：共享中断请求线和响应线
			响应速度中等：比软件查询快
			扩展方便：可串联多个设备
		- 缺点：
			优先级固定：设备位置决定，无法动态调整
			可靠性问题：链中任一设备故障影响后续所有设备
			延迟累积：中断响应信号需传递整个链
			灵活性差：添加/移除设备需重新布线
	
	 - 总线仲裁法（中断控制器法）
	
		> 专用中断控制器集中管理所有中断源，进行优先级仲裁后向CPU发送单个中断请求。
	
		- 优点：
			灵活优先级：可编程设置和动态调整
			CPU负担轻：仲裁由专用硬件完成
			功能丰富：支持嵌套、屏蔽、向量化等
			扩展性好：标准接口，易于扩展
		- 缺点：
			硬件成本增加：需要额外中断控制器芯片
			响应延迟：增加一级仲裁环节
			配置复杂：需要初始化编程
			单点故障风险：控制器故障导致所有中断失效
	
	- 中断向量表法（向量中断）
	
		> 每个中断源对应唯一向量号，中断发生时设备直接提供向量号，CPU查表跳转到相应服务程序。
	
		- 优点：
			响应速度最快：直接跳转，无需查询或仲裁
			灵活性最高：向量号可编程映射
			支持丰富特性：可轻松实现优先级、嵌套等
			软件接口清晰：向量表统一管理所有中断
		- 缺点：
			硬件复杂度高：需要向量号生成和传输机制
			资源需求大：需要向量表存储空间
			配置管理复杂：向量表需正确初始化和维护
			安全性考虑：需要保护向量表不被篡改
- 中断优先级控制
	- 多中断源系统中，对服务的要求紧迫程度不同，所以需要对紧迫的中断源分配最高优先级
	- 当不同优先级的多个中断源同时提出中断请求时，应优先响应最高优先级的
	- 当CPU 正在对 某一个中断源服务是，由比他还高优先级的中断请求，CPU应暂时中断正在执行的中断服务程序，转而执行优先级高的，这种情况叫中断嵌套，即一个重点服务中嵌套这另一个中断服务程序

### 3.4 直接存储器存取方式
	
### 3.5 输入输出处理机（IOP）

## 4. 总线结构

### 4.1 总线的分类
### 4.2 常见总线